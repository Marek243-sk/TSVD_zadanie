{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b439200a",
   "metadata": {},
   "source": [
    "### Načítanie knižníc a vytvorenie Spark session\n",
    "\n",
    "Importujú sa potrebné knižnice: `pyspark` pre prácu s veľkými dátami, `numpy` pre numerické operácie a `matplotlib` na vizualizáciu. Následne sa vytvára Spark session s názvom `zadanieTSVD`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a8f43c-d73c-459d-84c7-c2f0b1cc1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b514ed09-237c-4a4b-9d6d-f028662cce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"zadanieTSVD\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753af108",
   "metadata": {},
   "source": [
    "### Načítanie a zlúčenie datasetov\n",
    "\n",
    "Načítavajú sa dva samostatné datasety: trénovací (`train.csv`) a testovací (`test.csv`). Po ich načítaní sa spoja do jedného veľkého datasetu a zároveň vypíše počet riadkov pred a po zlúčení.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3f7df7-34ab-44ee-83c3-979b9f791891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 256657, Test rows: 170872\n",
      "Merged rows: 427529\n"
     ]
    }
   ],
   "source": [
    "## Načítanie a spojenie datasetov ##\n",
    "\n",
    "train_df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
    "test_df  = spark.read.csv(\"test.csv\", header=True, inferSchema=True)\n",
    "\n",
    "#odtstranenie Accident_Severity ako cieloveho atributu\n",
    "train_df = train_df.drop(\"Accident_Severity\")\n",
    "test_df = test_df.drop(\"Accident_Severity\")\n",
    "\n",
    "train_df = train_df.drop(\"Casualty_Severity\")\n",
    "test_df = test_df.drop(\"Casualty_Severity\")\n",
    "\n",
    "train_count = train_df.count()\n",
    "test_count = test_df.count()\n",
    "print(f\"Train rows: {train_count}, Test rows: {test_count}\")\n",
    "\n",
    "data_df = train_df.unionByName(test_df)\n",
    "merged_count = data_df.count()\n",
    "print(f\"Merged rows: {merged_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15747ba",
   "metadata": {},
   "source": [
    "### Príprava atribútov pre klasifikáciu\n",
    "\n",
    "Zo zlúčeného datasetu sa odstraňuje nepotrebný stĺpec `id`, a zvyšné stĺpce sa transformujú do jedného vektora pomocou `VectorAssembler`, ktorý vytvorí nový stĺpec `features` – vstup pre model KMeans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f50659-183e-40c0-bc9b-f044fa7ce105",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Príprava atribútov ##\n",
    "\n",
    "feature_cols = data_df.columns.copy()\n",
    "if 'id' in feature_cols:\n",
    "    feature_cols.remove('id')\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_feat = assembler.transform(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba431d0",
   "metadata": {},
   "source": [
    "### Trénovanie KMeans modelu\n",
    "\n",
    "Používa sa KMeans algoritmus na rozdelenie dát do `k=3` klastrov. Výsledný model sa uloží.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986be94b-0419-471a-9067-68611e99dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trénovanie K-Means ##\n",
    "\n",
    "k = 3\n",
    "kmeans = KMeans(k=k, featuresCol=\"features\", predictionCol=\"prediction\", seed=42)\n",
    "model = kmeans.fit(df_feat)\n",
    "# Uloženie modelu\n",
    "model.save(\"kmeans__model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c2a81",
   "metadata": {},
   "source": [
    "### Načítanie uloženého modelu\n",
    "\n",
    "Model, ktorý bol uložený sa načíta späť pomocou `KMeansModel.load`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9d0ffc-f5d9-416a-827a-52a6ba4aa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Načítanie modelu ##\n",
    "\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "loaded_model = KMeansModel.load(\"kmeans__model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900a3cf",
   "metadata": {},
   "source": [
    "### Detekcia anomálií\n",
    "\n",
    "Získajú sa centroidy (stredy) jednotlivých klastrov. Pomocou UDF funkcie sa vypočíta vzdialenosť každého bodu od svojho klastrového centroidu. Potom sa na základe 95. percentilu týchto vzdialeností nastaví prah, nad ktorým sa záznam považuje za anomáliu. Anomálie sa označia stĺpcom `anomaly`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53e31f0-77fc-4e5e-a284-6cdf9c9e9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detekcia anomálií ##\n",
    "\n",
    "## Centroidy algoritmu##\n",
    "centers = model.clusterCenters()\n",
    "## UDF na výpočet vzdialenosti ##\n",
    "@udf(returnType=\"double\")\n",
    "def calc_dist_udf(features, cluster):\n",
    "    center = centers[cluster]\n",
    "    diff = np.array(features) - center\n",
    "    return float(np.sqrt(np.dot(diff, diff)))\n",
    "\n",
    "## Pridanie stĺpca \"distance\" ##\n",
    "df_dist = model.transform(df_feat) \\\n",
    "    .withColumn(\"distance\", calc_dist_udf(col(\"features\"), col(\"prediction\")))\n",
    "## 95. percentil ako prah anomálie ##\n",
    "threshold = df_dist.approxQuantile(\"distance\", [0.95], 0.0)[0]\n",
    "## Pridanie príznaku anomálie ##\n",
    "df_anom = df_dist.withColumn(\"anomaly\", col(\"distance\") > threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41051d",
   "metadata": {},
   "source": [
    "### Uloženie výsledkov do CSV\n",
    "\n",
    "Vyfiltrované výsledky bez stĺpca `features` sa spoja do jedného CSV súboru a uložia sa do `data_with__anomalies.csv` a vypíše sa použitý prah pre detekciu anomálií.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1baad5e3-c53c-4fca-84dc-a2fd17550fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Výsledky uložené do 'data_with__anomalies.csv'. Anomálny prah = 162.3869.\n"
     ]
    }
   ],
   "source": [
    "## Uloženie výsledkov do CSV ##\n",
    "\n",
    "output_cols = [c for c in df_anom.columns if c != 'features']\n",
    "# Spojíme partičky do jedného súboru\n",
    "single_df = df_anom.select(*output_cols).coalesce(1)\n",
    "single_df.write.csv(\"data___with___anomalies.csv\", header=True)\n",
    "print(f\"Výsledky uložené do 'data_with__anomalies.csv'. Anomálny prah = {threshold:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ebc672",
   "metadata": {},
   "source": [
    "### Zobrazenie výsledkov klastrovania\n",
    "\n",
    "Na záver sa vypočíta a zobrazí počet záznamov v jednotlivých klastroch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d2ce1fe-8528-4499-8f02-931891e5bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Počet záznamov v jednotlivých klastroch:\n",
      "   prediction   count\n",
      "0           1  180295\n",
      "1           2  192009\n",
      "2           0   55225\n"
     ]
    }
   ],
   "source": [
    "## Zobrazenie výsledkov ##\n",
    "\n",
    "cluster_sizes = df_anom.groupBy(\"prediction\").count().toPandas()\n",
    "print(\"Počet záznamov v jednotlivých klastroch:\")\n",
    "print(cluster_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b69ef5-7824-4051-baf0-b0c140b09379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
