{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc932977-a20f-4058-9954-0a7e3e8df012",
   "metadata": {},
   "source": [
    "### Knižnice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f09d2e19-ea68-4c42-9865-e51b026b0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, LinearSVC,\n",
    "                                       OneVsRest, NaiveBayes, RandomForestClassifier,\n",
    "                                       ClassificationModel)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927ffd1-4f70-4ac9-b022-449a3b1bbfcb",
   "metadata": {},
   "source": [
    "### Inicializácia SparkSession a načítanie dát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb7a26b3-18f1-45fc-b36f-5d79e38d4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"zadanieTSVD\").getOrCreate()\n",
    "# Načítanie dát\n",
    "train_df = spark.read.csv(\"DATA/train_predspracovane.csv\", header=True, inferSchema=True)\n",
    "test_df = spark.read.csv(\"DATA/test_predspracovane.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e752a1ab-14d7-4f87-87ce-8ad4fa196aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------\n",
      " Bus_or_Coach_Passenger                        | 0.0  \n",
      " 1st_Road_Class                                | 0.0  \n",
      " Urban_or_Rural_Area2                          | 0.0  \n",
      " Road_Type                                     | 0.0  \n",
      " Casualty_Class                                | 0.0  \n",
      " Pedestrian_Location                           | 0.0  \n",
      " Special_Conditions_at_Site                    | 0.0  \n",
      " Carriageway_Hazards                           | 0.0  \n",
      " Junction_Control                              | 0.0  \n",
      " Vehicle_Type                                  | 0.0  \n",
      " Urban_or_Rural_Area10                         | 0.0  \n",
      " Weather_Conditions                            | 0.0  \n",
      " Age_Band_of_Casualty                          | 0.0  \n",
      " Did_Police_Officer_Attend_Scene_of_Accident13 | 0.0  \n",
      " Local_Authority_(District)                    | 0.0  \n",
      " Vehicle_Leaving_Carriageway                   | 0.0  \n",
      " Road_Surface_Conditions                       | 0.0  \n",
      " Casualty_Severity                             | 0.0  \n",
      " Casualty_Type                                 | 0.0  \n",
      " Pedestrian_Movement                           | 0.0  \n",
      " Sex_of_Casualty                               | 0.0  \n",
      " Light_Conditions                              | 0.0  \n",
      " Number_of_Vehicles                            | 2.0  \n",
      " Number_of_Casualties                          | 1.0  \n",
      " Local_Authority_(Highway)                     | 5.0  \n",
      " Pedestrian_Crossing_Physical_Facilities       | 0.0  \n",
      " 2nd_Road_Class                                | 0.0  \n",
      " Day_of_Week                                   | 3.0  \n",
      " Police_Force                                  | 1.0  \n",
      " Junction_Detail                               | 1.0  \n",
      " Speed_limit                                   | 30.0 \n",
      " Did_Police_Officer_Attend_Scene_of_Accident31 | 0.0  \n",
      " Car_Passenger                                 | 0.0  \n",
      " Accident_Severity                             | 3    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(n=1,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70e0ee4d-ebaf-4e27-8fa0-589bf45b488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA: 256657\n",
      "TEST DATA: 170872\n",
      "--------------------\n",
      "SPOLU: 427529\n",
      "=========================================\n",
      "PO ROZDELENÍ TRAIN NA TRAIN A VAL (80:20)\n",
      "--------------------\n",
      "TRAIN: 205326.0\n",
      "VAL: 51331.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN DATA: {train_df.count()}\\nTEST DATA: {test_df.count()}\\n{20*'-'}\\nSPOLU: {train_df.count()+test_df.count()}\\n\\\n",
    "{41*'='}\\nPO ROZDELENÍ TRAIN NA TRAIN A VAL (80:20)\\n{20*'-'}\\nTRAIN: {round(train_df.count()*0.8,0)}\\nVAL: {round(train_df.count()*0.2,0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b4194-d2a1-49fc-b309-b18efdedf9bd",
   "metadata": {},
   "source": [
    "### Príprava dát pred modelovaním"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec3279c9-ea21-4d3f-a734-188c1f8c3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(df: DataFrame, label_col: str, train_ratio: float, seed: int):\n",
    "    labels = df.select(label_col).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    train_parts = []\n",
    "    val_parts = []\n",
    "    \n",
    "    for lbl in labels:\n",
    "        subset = df.filter(col(label_col) == lbl)\n",
    "        train_subset, val_subset = subset.randomSplit([train_ratio, 1 - train_ratio], seed=seed)\n",
    "        train_parts.append(train_subset)\n",
    "        val_parts.append(val_subset)\n",
    "    \n",
    "    train_set = train_parts[0]\n",
    "    val_set = val_parts[0]\n",
    "    for i in range(1, len(train_parts)):\n",
    "        train_set = train_set.union(train_parts[i])\n",
    "        val_set = val_set.union(val_parts[i])\n",
    "    \n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae19bd88-08b3-4e46-8c21-0c05f694fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = stratified_split(train_df, label_col=\"Accident_Severity\", train_ratio=0.8, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbc8b028-9135-41e3-b994-8b8f014c852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA: 205542\n",
      "VAL DATA: 51115\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN DATA: {train_df.count()}\\nVAL DATA: {val_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ff9184c-bef4-4e99-a055-5cb1bdf9167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cieľový atribút a predikujúce atribúty\n",
    "label_col = \"Accident_Severity\"\n",
    "feature_cols = [c for c in train_df.columns if c != label_col]\n",
    "\n",
    "# Indexovanie kategórií\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"keep\")\n",
    "            for col in feature_cols if str(train_df.schema[col].dataType) == \"StringType\"]\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "# Zoznam vstupných príznakov po indexovaní\n",
    "indexed_features = [col+\"_index\" if str(train_df.schema[col].dataType) == \"StringType\" else col for col in feature_cols]\n",
    "assembler = VectorAssembler(inputCols=indexed_features, outputCol=\"features\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [label_indexer, assembler])\n",
    "\n",
    "# Fit len na TRAIN SET\n",
    "pipeline_model = pipeline.fit(train_set)\n",
    "\n",
    "# Aplikácia na všetky sety\n",
    "train_prepared = pipeline_model.transform(train_set)\n",
    "val_prepared = pipeline_model.transform(val_set)\n",
    "test_prepared = pipeline_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3523c-5527-43de-b426-ac15bffa5850",
   "metadata": {},
   "source": [
    "### Funkcie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06205b4c-16d0-4c4c-bdf0-4cb83ce0c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcia vyberie model podľa typu\n",
    "def get_model(model_type: str, df: DataFrame) -> ClassificationModel:\n",
    "    if model_type == \"dt\":\n",
    "        return DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"svm\":\n",
    "        base = LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
    "        n_classes = df.select(\"label\").distinct().count()\n",
    "        return base if n_classes == 2 else OneVsRest(classifier=base, featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"nb\":\n",
    "        return NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"rf\":\n",
    "        return RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"gbt\":\n",
    "        return GBTClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "    else:\n",
    "        raise ValueError(\"Nepodporovaný model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8267482b-1efb-4dc2-a104-1a9345a68d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcia na optimalizáciu hyperparametrov pomocou gridsearch\n",
    "def grid_search_model(val_df: DataFrame, model_type: str) -> tuple[ClassificationModel, list]:\n",
    "\n",
    "    if model_type == \"svm\":\n",
    "        base_model = LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
    "        n_classes = val_prepared.select(\"label\").distinct().count()\n",
    "\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(base_model.regParam, [0.01,0.1]) \\\n",
    "            .addGrid(base_model.maxIter, [50,100]) \\\n",
    "            .build()\n",
    "        \n",
    "        model = base_model if n_classes == 2 else OneVsRest(classifier=base_model,\n",
    "                                                             labelCol=\"label\",\n",
    "                                                             featuresCol=\"features\")\n",
    "    else:\n",
    "        model = get_model(model_type, val_df)\n",
    "\n",
    "        if model_type == \"dt\":\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(model.maxDepth, [2,5,10]) \\\n",
    "                .addGrid(model.minInstancesPerNode, [1,2,5]) \\\n",
    "                .addGrid(model.maxBins, [10,20,30,40]) \\\n",
    "                .build()\n",
    "        elif model_type == \"rf\":\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(model.numTrees, [20,50]) \\\n",
    "                .addGrid(model.maxDepth, [5,10]) \\\n",
    "                .build()\n",
    "        elif model_type == \"gbt\":\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(model.maxIter, [10,20]) \\\n",
    "                .addGrid(model.maxDepth, [3,5]) \\\n",
    "                .build()\n",
    "        elif model_type == \"nb\":\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(model.smoothing, [0.5,1.0,1.5]) \\\n",
    "                .build()\n",
    "        else:\n",
    "            raise ValueError(\"Grid search nie je implementovaný pre tento model.\")\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    cv = CrossValidator(estimator=model,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator=evaluator,\n",
    "                        numFolds=3,\n",
    "                        parallelism=2)\n",
    "\n",
    "    best_model = cv.fit(val_prepared)\n",
    "    return best_model.bestModel, paramGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fbae4736-b7e7-485d-8042-92c29e6e2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(train_or_val_df: DataFrame, test_df: DataFrame, model_type: str, grid_search: bool) -> ClassificationModel:\n",
    "\n",
    "    if grid_search:\n",
    "        print(f\"Optimalizácia hyperparametrov pre {model_type.upper()}\")\n",
    "        model, paramGrid = grid_search_model(train_or_val_df, model_type=model_type)\n",
    "\n",
    "        # Zobrazenie najlepších hyperparametrov\n",
    "        print(\"Najlepšie hyperparametre:\")\n",
    "        tuned_param_names = {param.name for paramMap in paramGrid for param in paramMap}\n",
    "        for param, value in model.extractParamMap().items():\n",
    "            if param.name in tuned_param_names:\n",
    "                print(f\"  {param.name}: {value}\")\n",
    "    else:\n",
    "        model = get_model(model_type, train_prepared)\n",
    "        model = model.fit(train_prepared)\n",
    "\n",
    "    # Predikcia\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    # Vyhodnotenie\n",
    "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    conf_matrix = metrics.confusionMatrix().toArray().astype(int)\n",
    "\n",
    "    # Získanie názvov tried\n",
    "    class_labels = sorted(test_df.select(\"label\").distinct().rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "    # Výpis confusion matrix\n",
    "    print(f\"\\nConfusion Matrix {model_type.upper()}:\")\n",
    "    print(\"Predicted/Actual  \", \"  \".join([f\"{label:>8}\" for label in class_labels]))\n",
    "    \n",
    "    for i, row in enumerate(conf_matrix):\n",
    "        print(f\"{class_labels[i]:>15}  \", \"  \".join([f\"{int(x):>8}\" for x in row]))\n",
    "\n",
    "    accuracy = metrics.accuracy\n",
    "    precision = metrics.weightedPrecision\n",
    "    recall = metrics.weightedRecall\n",
    "    f1 = metrics.weightedFMeasure()\n",
    "    print(f\"\\nVýsledky pre {model_type.upper()}:\")\n",
    "    print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall:    {recall:.3f}\")\n",
    "    print(f\"F1 Score:  {f1:.3f}\")\n",
    "\n",
    "    # MCC\n",
    "    y_true = predictions.select(\"label\").toPandas()[\"label\"]\n",
    "    y_pred = predictions.select(\"prediction\").toPandas()[\"prediction\"]\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    print(f\"Matthews Correlation Coefficient (MCC) {model_type.upper()}: {mcc:.3f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7215a-e031-4cf0-b29c-1d08dae70897",
   "metadata": {},
   "source": [
    "Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6e160c2-6275-43d4-8774-2c75e6a98bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre DT\n",
      "Najlepšie hyperparametre:\n",
      "  maxBins: 30\n",
      "  maxDepth: 5\n",
      "  minInstancesPerNode: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix DT:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143785         0        29\n",
      "            1.0       7056     16778        26\n",
      "            2.0        927       600      1671\n",
      "\n",
      "Výsledky pre DT:\n",
      "Accuracy:  0.949\n",
      "Precision: 0.950\n",
      "Recall:    0.949\n",
      "F1 Score:  0.945\n",
      "Matthews Correlation Coefficient (MCC) DT: 0.803\n"
     ]
    }
   ],
   "source": [
    "dt_optimized = train_and_evaluate_model(train_or_val_df=val_prepared, test_df=test_prepared, model_type=\"dt\", grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1bae679-5c4f-40f0-bd9f-f6c9f7d350da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix DT:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143801         0        13\n",
      "            1.0       7067     16786         7\n",
      "            2.0        934       601      1663\n",
      "\n",
      "Výsledky pre DT:\n",
      "Accuracy:  0.950\n",
      "Precision: 0.951\n",
      "Recall:    0.950\n",
      "F1 Score:  0.945\n",
      "Matthews Correlation Coefficient (MCC) DT: 0.803\n"
     ]
    }
   ],
   "source": [
    "dt = train_and_evaluate_model(train_or_val_df=train_prepared, test_df=test_prepared, model_type=\"dt\", grid_search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0393f-b772-4e07-a347-b30f33fac54f",
   "metadata": {},
   "source": [
    "Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51aff2b0-bca0-4be6-9c92-d4d2325500b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix SVM:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143814         0         0\n",
      "            1.0       7206     16654         0\n",
      "            2.0        974      2224         0\n",
      "\n",
      "Výsledky pre SVM:\n",
      "Accuracy:  0.939\n",
      "Precision: 0.920\n",
      "Recall:    0.939\n",
      "F1 Score:  0.927\n",
      "Matthews Correlation Coefficient (MCC) SVM: 0.757\n"
     ]
    }
   ],
   "source": [
    "svm = train_and_evaluate_model(train_or_val_df=val_df, test_df=test_prepared, model_type=\"svm\", grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "75d3b690-55c0-4cfe-bf95-4039e45cefa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre SVM\n",
      "Najlepšie hyperparametre:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix SVM:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143814         0         0\n",
      "            1.0       7227     16633         0\n",
      "            2.0        974      2224         0\n",
      "\n",
      "Výsledky pre SVM:\n",
      "Accuracy:  0.939\n",
      "Precision: 0.919\n",
      "Recall:    0.939\n",
      "F1 Score:  0.927\n",
      "Matthews Correlation Coefficient (MCC) SVM: 0.757\n"
     ]
    }
   ],
   "source": [
    "svm_optimized = train_and_evaluate_model(train_or_val_df=val_df, test_df=test_prepared, model_type=\"svm\", grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bed23-bb85-4611-b166-18410409b68c",
   "metadata": {},
   "source": [
    "Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "95e8b70b-19a8-4aa7-94e8-662f3c1ff84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre NB\n",
      "Najlepšie hyperparametre:\n",
      "  smoothing: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix NB:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0      89098      9442     45274\n",
      "            1.0       5210      8070     10580\n",
      "            2.0        352       979      1867\n",
      "\n",
      "Výsledky pre NB:\n",
      "Accuracy:  0.580\n",
      "Precision: 0.854\n",
      "Recall:    0.580\n",
      "F1 Score:  0.683\n",
      "Matthews Correlation Coefficient (MCC) NB: 0.234\n"
     ]
    }
   ],
   "source": [
    "nb_optimized = train_and_evaluate_model(train_or_val_df=val_df, test_df=test_prepared, model_type=\"nb\", grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120fb37a-588d-4a45-b61e-6b8791f515b0",
   "metadata": {},
   "source": [
    "Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62d96582-88a4-475b-b0ef-7598b58ee0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1.43725e+05 0.00000e+00 0.00000e+00]\n",
      " [7.11000e+03 1.69000e+04 0.00000e+00]\n",
      " [9.45000e+02 2.15900e+03 3.30000e+01]]\n",
      "Accuracy: 0.940\n",
      "Precision: 0.939\n",
      "Recall: 0.940\n",
      "F1 Score: 0.929\n",
      "MCC: 0.763\n"
     ]
    }
   ],
   "source": [
    "# Definovanie labelu a vstupov\n",
    "label_col = \"Accident_Severity\"\n",
    "feature_cols = [c for c in train_df.columns if c != label_col]\n",
    "\n",
    "# Indexovanie\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"keep\")\n",
    "            for col in feature_cols if str(train_df.schema[col].dataType) == \"StringType\"]\n",
    "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "# Vektor príznakov\n",
    "indexed_features = [col+\"_index\" if str(train_df.schema[col].dataType) == \"StringType\" else col for col in feature_cols]\n",
    "assembler = VectorAssembler(inputCols=indexed_features, outputCol=\"features\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [label_indexer, assembler])\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "train_prepared = pipeline_model.transform(train_df)\n",
    "test_prepared = pipeline_model.transform(test_df)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "rf_model = rf.fit(train_prepared)\n",
    "rf_predictions = rf_model.transform(test_prepared)\n",
    "\n",
    "rf_pl = rf_predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
    "rf_metrics = MulticlassMetrics(rf_pl)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(rf_metrics.confusionMatrix().toArray())\n",
    "print(f\"Accuracy: {rf_metrics.accuracy:.3f}\")\n",
    "print(f\"Precision: {rf_metrics.weightedPrecision:.3f}\")\n",
    "print(f\"Recall: {rf_metrics.weightedRecall:.3f}\")\n",
    "print(f\"F1 Score: {rf_metrics.weightedFMeasure():.3f}\")\n",
    "\n",
    "rf_y_true = rf_predictions.select(\"label\").toPandas()[\"label\"]\n",
    "rf_y_pred = rf_predictions.select(\"prediction\").toPandas()[\"prediction\"]\n",
    "rf_mcc = matthews_corrcoef(rf_y_true, rf_y_pred)\n",
    "print(f\"MCC: {rf_mcc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec45a4-cc12-4026-8838-d6eaa4137185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792265b-a989-4058-9c2e-a2b0f9e1fd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3584580-34c4-4c59-897b-d05e62ba5b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c5094-84ce-4197-80b3-e7913c7e3303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d98a1c-90c2-4562-ae86-15fb3da05bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient-boosted trees nefunguje pre viactriednu klasifikaciu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d4abb-d319-462e-a4a2-6ad68e1895be",
   "metadata": {},
   "source": [
    "Gradient-boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "896d411a-0fc8-423f-a9ad-fe498c5d8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac165a5-debb-430b-856b-2e756e7d7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definovanie labelu a vstupov\n",
    "label_col = \"Accident_Severity\"\n",
    "feature_cols = [c for c in train_df.columns if c != label_col]\n",
    "\n",
    "# Indexovanie\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"keep\")\n",
    "            for col in feature_cols if str(train_df.schema[col].dataType) == \"StringType\"]\n",
    "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "# Vektor príznakov\n",
    "indexed_features = [col+\"_index\" if str(train_df.schema[col].dataType) == \"StringType\" else col for col in feature_cols]\n",
    "assembler = VectorAssembler(inputCols=indexed_features, outputCol=\"features\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [label_indexer, assembler])\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "train_prepared = pipeline_model.transform(train_df)\n",
    "test_prepared = pipeline_model.transform(test_df)\n",
    "\n",
    "\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "gbt_model = gbt.fit(train_prepared)\n",
    "gbt_predictions = gbt_model.transform(test_prepared)\n",
    "\n",
    "gbt_pl = gbt_predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
    "gbt_metrics = MulticlassMetrics(gbt_pl)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(gbt_metrics.confusionMatrix().toArray())\n",
    "print(f\"Accuracy: {gbt_metrics.accuracy:.3f}\")\n",
    "print(f\"Precision: {gbt_metrics.weightedPrecision:.3f}\")\n",
    "print(f\"Recall: {gbt_metrics.weightedRecall:.3f}\")\n",
    "print(f\"F1 Score: {gbt_metrics.weightedFMeasure():.3f}\")\n",
    "\n",
    "gbt_y_true = gbt_predictions.select(\"label\").toPandas()[\"label\"]\n",
    "gbt_y_pred = gbt_predictions.select(\"prediction\").toPandas()[\"prediction\"]\n",
    "gbt_mcc = matthews_corrcoef(gbt_y_true, gbt_y_pred)\n",
    "print(f\"MCC: {gbt_mcc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ce2379f-0b40-459b-b299-621c9f8802cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[89446.  3791. 50577.]\n",
      " [ 4047.  8945. 10868.]\n",
      " [  324.  1026.  1848.]]\n",
      "Accuracy: 0.587\n",
      "Precision: 0.894\n",
      "Recall: 0.587\n",
      "F1 Score: 0.701\n",
      "Matthews Correlation Coefficient (MCC): 0.274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NaiveBayesModel: uid=NaiveBayes_6f139f75449d, modelType=multinomial, numClasses=3, numFeatures=33"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Len obyčajný model:\n",
    "train_and_evaluate_model(train_prepared, test_prepared, model_type=\"naive_bayes\")\n",
    "\n",
    "# S grid search optimalizáciou:\n",
    "train_and_evaluate_model(train_prepared, test_prepared, model_type=\"random_forest\", grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7fa7f-3c8d-40e9-9e62-55c2d62459d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
