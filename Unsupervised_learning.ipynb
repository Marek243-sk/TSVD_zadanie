{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a8f43c-d73c-459d-84c7-c2f0b1cc1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b514ed09-237c-4a4b-9d6d-f028662cce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"zadanieTSVD\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c3f7df7-34ab-44ee-83c3-979b9f791891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 256657, Test rows: 170872\n",
      "Merged rows: 427529 (should be 427529)\n"
     ]
    }
   ],
   "source": [
    "## Načítanie a spojenie datasetov ##\n",
    "\n",
    "train_df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
    "test_df  = spark.read.csv(\"test.csv\", header=True, inferSchema=True)\n",
    "\n",
    "train_count = train_df.count()\n",
    "test_count = test_df.count()\n",
    "print(f\"Train rows: {train_count}, Test rows: {test_count}\")\n",
    "\n",
    "data_df = train_df.unionByName(test_df)\n",
    "merged_count = data_df.count()\n",
    "print(f\"Merged rows: {merged_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f50659-183e-40c0-bc9b-f044fa7ce105",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Príprava atribútov ##\n",
    "\n",
    "feature_cols = data_df.columns.copy()\n",
    "if 'id' in feature_cols:\n",
    "    feature_cols.remove('id')\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_feat = assembler.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986be94b-0419-471a-9067-68611e99dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trénovanie K-Means ##\n",
    "\n",
    "k = 3\n",
    "kmeans = KMeans(k=k, featuresCol=\"features\", predictionCol=\"prediction\", seed=42)\n",
    "model = kmeans.fit(df_feat)\n",
    "# Uloženie modelu\n",
    "model.save(\"kmeans_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c9d0ffc-f5d9-416a-827a-52a6ba4aa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Načítanie modelu ##\n",
    "\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "loaded_model = KMeansModel.load(\"kmeans_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53e31f0-77fc-4e5e-a284-6cdf9c9e9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detekcia anomálií ##\n",
    "\n",
    "## Centroidy algoritmu##\n",
    "centers = model.clusterCenters()\n",
    "## UDF na výpočet vzdialenosti ##\n",
    "@udf(returnType=\"double\")\n",
    "def calc_dist_udf(features, cluster):\n",
    "    center = centers[cluster]\n",
    "    diff = np.array(features) - center\n",
    "    return float(np.sqrt(np.dot(diff, diff)))\n",
    "\n",
    "## Pridanie stĺpca \"distance\" ##\n",
    "df_dist = model.transform(df_feat) \\\n",
    "    .withColumn(\"distance\", calc_dist_udf(col(\"features\"), col(\"prediction\")))\n",
    "## 95. percentil ako prah anomálie ##\n",
    "threshold = df_dist.approxQuantile(\"distance\", [0.95], 0.0)[0]\n",
    "## Pridanie príznaku anomálie ##\n",
    "df_anom = df_dist.withColumn(\"anomaly\", col(\"distance\") > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1baad5e3-c53c-4fca-84dc-a2fd17550fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Výsledky uložené do 'data_with_anomalies_spark.csv'. Anomálny prah = 162.3886.\n"
     ]
    }
   ],
   "source": [
    "# --- 5) Uloženie výsledkov do jediného CSV ---\n",
    "output_cols = [c for c in df_anom.columns if c != 'features']\n",
    "# Spojíme partičky do jedného súboru\n",
    "single_df = df_anom.select(*output_cols).coalesce(1)\n",
    "single_df.write.csv(\"data_with_anomalies.csv\", header=True)\n",
    "print(f\"Výsledky uložené do 'data_with_anomalies_spark.csv'. Anomálny prah = {threshold:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d2ce1fe-8528-4499-8f02-931891e5bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Počet záznamov v jednotlivých klastroch:\n",
      "   prediction   count\n",
      "0           1  180295\n",
      "1           2  192009\n",
      "2           0   55225\n"
     ]
    }
   ],
   "source": [
    "# Zobrazenie výsledkov #\n",
    "\n",
    "cluster_sizes = df_anom.groupBy(\"prediction\").count().toPandas()\n",
    "print(\"Počet záznamov v jednotlivých klastroch:\")\n",
    "print(cluster_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
