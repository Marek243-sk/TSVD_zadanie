{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc932977-a20f-4058-9954-0a7e3e8df012",
   "metadata": {},
   "source": [
    "### Knižnice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f09d2e19-ea68-4c42-9865-e51b026b0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, LinearSVC,\n",
    "                                       OneVsRest, NaiveBayes, RandomForestClassifier,\n",
    "                                       GBTClassifier, ClassificationModel)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927ffd1-4f70-4ac9-b022-449a3b1bbfcb",
   "metadata": {},
   "source": [
    "### Inicializácia SparkSession a načítanie dát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7a26b3-18f1-45fc-b36f-5d79e38d4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"zadanieTSVD\").getOrCreate()\n",
    "# Načítanie dát\n",
    "train_df = spark.read.csv(\"DATA/train.csv\", header=True, inferSchema=True)\n",
    "test_df = spark.read.csv(\"DATA/test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7ee6ab-eabb-4645-a05c-fda7349fbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.na.drop()\n",
    "# test_df = test_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e0ee4d-ebaf-4e27-8fa0-589bf45b488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA: 256657\n",
      "TEST DATA: 170872\n",
      "--------------------\n",
      "SPOLU: 427529\n",
      "=========================================\n",
      "PO ROZDELENÍ TRAIN NA TRAIN A VAL (80:20)\n",
      "--------------------\n",
      "TRAIN: 205326.0\n",
      "VAL: 51331.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN DATA: {train_df.count()}\\nTEST DATA: {test_df.count()}\\n{20*'-'}\\nSPOLU: {train_df.count()+test_df.count()}\\n\\\n",
    "{41*'='}\\nPO ROZDELENÍ TRAIN NA TRAIN A VAL (80:20)\\n{20*'-'}\\nTRAIN: {round(train_df.count()*0.8,0)}\\nVAL: {round(train_df.count()*0.2,0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b4194-d2a1-49fc-b309-b18efdedf9bd",
   "metadata": {},
   "source": [
    "### Príprava dát pred modelovaním"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3279c9-ea21-4d3f-a734-188c1f8c3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(df: DataFrame, label_col: str, train_ratio: float, seed: int) -> Tuple[DataFrame, DataFrame]:\n",
    "    labels = df.select(label_col).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    train_parts = []\n",
    "    val_parts = []\n",
    "    \n",
    "    for lbl in labels:\n",
    "        subset = df.filter(col(label_col) == lbl)\n",
    "        train_subset, val_subset = subset.randomSplit([train_ratio, 1 - train_ratio], seed=seed)\n",
    "        train_parts.append(train_subset)\n",
    "        val_parts.append(val_subset)\n",
    "    \n",
    "    train_set = train_parts[0]\n",
    "    val_set = val_parts[0]\n",
    "    for i in range(1, len(train_parts)):\n",
    "        train_set = train_set.union(train_parts[i])\n",
    "        val_set = val_set.union(val_parts[i])\n",
    "    \n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae19bd88-08b3-4e46-8c21-0c05f694fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = stratified_split(train_df, label_col=\"Accident_Severity\", train_ratio=0.8, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff9184c-bef4-4e99-a055-5cb1bdf9167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cieľový atribút a predikujúce atribúty\n",
    "label_col = \"Accident_Severity\"\n",
    "feature_cols = [c for c in train_df.columns if c != label_col]\n",
    "\n",
    "# Indexovanie kategórií\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"keep\")\n",
    "            for col in feature_cols if str(train_df.schema[col].dataType) == \"StringType\"]\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "# Zoznam vstupných príznakov po indexovaní\n",
    "indexed_features = [col+\"_index\" if str(train_df.schema[col].dataType) == \"StringType\" else col for col in feature_cols]\n",
    "assembler = VectorAssembler(inputCols=indexed_features, outputCol=\"features\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [label_indexer, assembler])\n",
    "\n",
    "# Fit len na TRAIN SET\n",
    "pipeline_model = pipeline.fit(train_set)\n",
    "\n",
    "# Aplikácia na všetky sety\n",
    "train_prepared = pipeline_model.transform(train_set)\n",
    "val_prepared = pipeline_model.transform(val_set)\n",
    "test_prepared = pipeline_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3523c-5527-43de-b426-ac15bffa5850",
   "metadata": {},
   "source": [
    "### Funkcie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06205b4c-16d0-4c4c-bdf0-4cb83ce0c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcia vyberie model podľa typu\n",
    "def get_model(model_type: str, df: DataFrame) -> ClassificationModel:\n",
    "    n_classes = df.select(\"label\").distinct().count()\n",
    "\n",
    "    if model_type == \"dt\":\n",
    "        model = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"nb\":\n",
    "        model = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"svm\":\n",
    "        base = LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
    "        model = base if n_classes == 2 else OneVsRest(classifier=base, featuresCol=\"features\", labelCol=\"label\")\n",
    "    elif model_type == \"gbt\":\n",
    "        base = GBTClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "        model = base if n_classes == 2 else OneVsRest(classifier=base, featuresCol=\"features\", labelCol=\"label\")\n",
    "    else:\n",
    "        raise ValueError(f\"Nepodporovaný model: {model_type}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8267482b-1efb-4dc2-a104-1a9345a68d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcia na optimalizáciu hyperparametrov pomocou gridsearch\n",
    "def grid_search_model(val_df: DataFrame, model_type: str) -> Tuple[ClassificationModel, list]:\n",
    "    model = get_model(model_type, val_df)\n",
    "\n",
    "    if model_type == \"dt\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.maxDepth, [2, 5, 10]) \\\n",
    "            .addGrid(model.minInstancesPerNode, [1, 2, 5]) \\\n",
    "            .addGrid(model.maxBins, [10, 20, 30]) \\\n",
    "            .build()\n",
    "    elif model_type == \"rf\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.numTrees, [20, 50]) \\\n",
    "            .addGrid(model.maxDepth, [5, 10]) \\\n",
    "            .build()\n",
    "    elif model_type == \"gbt\":\n",
    "        estimator = model.getClassifier() if isinstance(model, OneVsRest) else model\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(estimator.maxIter, [10, 20]) \\\n",
    "            .addGrid(estimator.maxDepth, [3, 5]) \\\n",
    "            .build()\n",
    "    elif model_type == \"nb\":\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.smoothing, [0.5, 1.0, 1.5]) \\\n",
    "            .build()\n",
    "    elif model_type == \"svm\":\n",
    "        estimator = model.getClassifier() if isinstance(model, OneVsRest) else model\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(estimator.regParam, [0.01, 0.1]) \\\n",
    "            .addGrid(estimator.maxIter, [50, 100]) \\\n",
    "            .build()\n",
    "    else:\n",
    "        raise ValueError(f\"Grid search nie je implementovaný pre model typu {model_type}\")\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    cv = CrossValidator(estimator=model,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator=evaluator,\n",
    "                        numFolds=3,\n",
    "                        parallelism=2)\n",
    "\n",
    "    best_model = cv.fit(val_df)\n",
    "    return best_model.bestModel, paramGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbae4736-b7e7-485d-8042-92c29e6e2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(\n",
    "    train_df: DataFrame,\n",
    "    val_df: DataFrame,\n",
    "    test_df: DataFrame,\n",
    "    model_type: str,\n",
    "    grid_search: bool\n",
    ") -> ClassificationModel:\n",
    "\n",
    "    if grid_search:\n",
    "        print(f\"Optimalizácia hyperparametrov pre {model_type.upper()}\")\n",
    "        \n",
    "        # Optimalizácia na validačnej množine\n",
    "        best_model_val, paramGrid = grid_search_model(val_df, model_type=model_type)\n",
    "\n",
    "        # Výpis najlepších hyperparametrov\n",
    "        print(\"Najlepšie hyperparametre:\")\n",
    "        tuned_param_names = {param.name for paramMap in paramGrid for param in paramMap}\n",
    "        for param, value in best_model_val.extractParamMap().items():\n",
    "            if param.name in tuned_param_names:\n",
    "                print(f\"  {param.name}: {value}\")\n",
    "\n",
    "        # Tréning modelu s optimalizovanými hyperparametrami na trénovacej množine\n",
    "        base_model = get_model(model_type, train_df)\n",
    "        tuned_params = best_model_val.extractParamMap()\n",
    "        model = base_model.copy(tuned_params)\n",
    "        model = model.fit(train_df)\n",
    "\n",
    "    else:\n",
    "        model = get_model(model_type, train_df)\n",
    "        model = model.fit(train_df)\n",
    "\n",
    "    # Predikcia\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    # Vyhodnotenie\n",
    "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    conf_matrix = metrics.confusionMatrix().toArray().astype(int)\n",
    "\n",
    "    # Získanie názvov tried\n",
    "    class_labels = sorted(test_df.select(\"label\").distinct().rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "    # Výpis confusion matrix\n",
    "    print(f\"\\nConfusion Matrix {model_type.upper()}:\")\n",
    "    print(\"Predicted/Actual  \", \"  \".join([f\"{label:>8}\" for label in class_labels]))\n",
    "    \n",
    "    for i, row in enumerate(conf_matrix):\n",
    "        print(f\"{class_labels[i]:>15}  \", \"  \".join([f\"{int(x):>8}\" for x in row]))\n",
    "\n",
    "    accuracy = metrics.accuracy\n",
    "    precision = metrics.weightedPrecision\n",
    "    recall = metrics.weightedRecall\n",
    "    f1 = metrics.weightedFMeasure()\n",
    "    print(f\"\\nVýsledky pre {model_type.upper()}:\")\n",
    "    print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall:    {recall:.3f}\")\n",
    "    print(f\"F1 Score:  {f1:.3f}\")\n",
    "\n",
    "    # MCC\n",
    "    y_true = predictions.select(\"label\").toPandas()[\"label\"]\n",
    "    y_pred = predictions.select(\"prediction\").toPandas()[\"prediction\"]\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    print(f\"Matthews Correlation Coefficient (MCC) {model_type.upper()}: {mcc:.3f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7215a-e031-4cf0-b29c-1d08dae70897",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1bae679-5c4f-40f0-bd9f-f6c9f7d350da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix DT:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143643        98         0\n",
      "            1.0       7037     16849         0\n",
      "            2.0        960       643      1642\n",
      "\n",
      "Výsledky pre DT:\n",
      "Accuracy:  0.949\n",
      "Precision: 0.950\n",
      "Recall:    0.949\n",
      "F1 Score:  0.945\n",
      "Matthews Correlation Coefficient (MCC) DT: 0.801\n"
     ]
    }
   ],
   "source": [
    "# Bez optimalizácie hyperparametrov\n",
    "dt = train_and_evaluate_model(train_df=train_prepared, val_df=None, test_df=test_prepared, model_type=\"dt\", grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e160c2-6275-43d4-8774-2c75e6a98bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre DT\n",
      "Najlepšie hyperparametre:\n",
      "  maxBins: 10\n",
      "  maxDepth: 5\n",
      "  minInstancesPerNode: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix DT:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143643        98         0\n",
      "            1.0       7037     16849         0\n",
      "            2.0        960       643      1642\n",
      "\n",
      "Výsledky pre DT:\n",
      "Accuracy:  0.949\n",
      "Precision: 0.950\n",
      "Recall:    0.949\n",
      "F1 Score:  0.945\n",
      "Matthews Correlation Coefficient (MCC) DT: 0.801\n"
     ]
    }
   ],
   "source": [
    "# S optimalizáciou hyperparametrov\n",
    "dt_optimized = train_and_evaluate_model(train_df=train_prepared, val_df=val_prepared, test_df=test_prepared, model_type=\"dt\", grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0393f-b772-4e07-a347-b30f33fac54f",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51aff2b0-bca0-4be6-9c92-d4d2325500b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix SVM:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143741         0         0\n",
      "            1.0       7228     16658         0\n",
      "            2.0        992      2253         0\n",
      "\n",
      "Výsledky pre SVM:\n",
      "Accuracy:  0.939\n",
      "Precision: 0.919\n",
      "Recall:    0.939\n",
      "F1 Score:  0.927\n",
      "Matthews Correlation Coefficient (MCC) SVM: 0.756\n"
     ]
    }
   ],
   "source": [
    "# Bez optimalizácie hyperparametrov\n",
    "svm = train_and_evaluate_model(train_df=train_prepared, val_df=None, test_df=test_prepared, model_type=\"svm\", grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75d3b690-55c0-4cfe-bf95-4039e45cefa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre SVM\n",
      "Najlepšie hyperparametre:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix SVM:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143741         0         0\n",
      "            1.0       7228     16658         0\n",
      "            2.0        992      2253         0\n",
      "\n",
      "Výsledky pre SVM:\n",
      "Accuracy:  0.939\n",
      "Precision: 0.919\n",
      "Recall:    0.939\n",
      "F1 Score:  0.927\n",
      "Matthews Correlation Coefficient (MCC) SVM: 0.756\n"
     ]
    }
   ],
   "source": [
    "# S optimalizáciou hyperparametrov\n",
    "svm_optimized = train_and_evaluate_model(train_df=train_prepared, val_df=val_prepared, test_df=test_prepared, model_type=\"svm\", grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bed23-bb85-4611-b166-18410409b68c",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb7cfbfd-d15e-4e30-bae8-f61b18346f83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix NB:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     132869      9978       894\n",
      "            1.0       6551     16111      1224\n",
      "            2.0        833      1867       545\n",
      "\n",
      "Výsledky pre NB:\n",
      "Accuracy:  0.875\n",
      "Precision: 0.881\n",
      "Recall:    0.875\n",
      "F1 Score:  0.878\n",
      "Matthews Correlation Coefficient (MCC) NB: 0.565\n"
     ]
    }
   ],
   "source": [
    "# Bez optimalizácie hyperparametrov\n",
    "nb = train_and_evaluate_model(train_df=train_prepared, val_df=None, test_df=test_prepared, model_type=\"nb\", grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95e8b70b-19a8-4aa7-94e8-662f3c1ff84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre NB\n",
      "Najlepšie hyperparametre:\n",
      "  smoothing: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix NB:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     132869      9978       894\n",
      "            1.0       6551     16111      1224\n",
      "            2.0        833      1867       545\n",
      "\n",
      "Výsledky pre NB:\n",
      "Accuracy:  0.875\n",
      "Precision: 0.881\n",
      "Recall:    0.875\n",
      "F1 Score:  0.878\n",
      "Matthews Correlation Coefficient (MCC) NB: 0.565\n"
     ]
    }
   ],
   "source": [
    "# S optimalizáciou hyperparametrov\n",
    "nb_optimized = train_and_evaluate_model(train_df=train_prepared, val_df=val_prepared, test_df=test_prepared, model_type=\"nb\", grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120fb37a-588d-4a45-b61e-6b8791f515b0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e85518-9c4f-4fba-b4fd-fc3e554b0e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix RF:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143741         0         0\n",
      "            1.0       7229     16657         0\n",
      "            2.0       1113      1282       850\n",
      "\n",
      "Výsledky pre RF:\n",
      "Accuracy:  0.944\n",
      "Precision: 0.944\n",
      "Recall:    0.944\n",
      "F1 Score:  0.937\n",
      "Matthews Correlation Coefficient (MCC) RF: 0.778\n"
     ]
    }
   ],
   "source": [
    "# Bez optimalizácie hyperparametrov\n",
    "rf = train_and_evaluate_model(train_df=train_prepared, val_df=None, test_df=test_prepared, model_type=\"rf\", grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c2682e6-49f1-4cc9-9a79-b8b0490b562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre RF\n",
      "Najlepšie hyperparametre:\n",
      "  maxDepth: 10\n",
      "  numTrees: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix RF:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143741         0         0\n",
      "            1.0       7229     16657         0\n",
      "            2.0       1113      1282       850\n",
      "\n",
      "Výsledky pre RF:\n",
      "Accuracy:  0.944\n",
      "Precision: 0.944\n",
      "Recall:    0.944\n",
      "F1 Score:  0.937\n",
      "Matthews Correlation Coefficient (MCC) RF: 0.778\n"
     ]
    }
   ],
   "source": [
    "# S optimalizáciou hyperparametrov\n",
    "rf_optimized = train_and_evaluate_model(train_df=train_prepared, val_df=val_prepared, test_df=test_prepared, model_type=\"rf\", grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d4abb-d319-462e-a4a2-6ad68e1895be",
   "metadata": {},
   "source": [
    "### Gradient-boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0702dc6a-ad87-4d95-86c8-7d0f9b522838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix GBT:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143706        35         0\n",
      "            1.0       7039     16845         2\n",
      "            2.0        957       624      1664\n",
      "\n",
      "Výsledky pre GBT:\n",
      "Accuracy:  0.949\n",
      "Precision: 0.950\n",
      "Recall:    0.949\n",
      "F1 Score:  0.945\n",
      "Matthews Correlation Coefficient (MCC) GBT: 0.803\n"
     ]
    }
   ],
   "source": [
    "# Bez optimalizácie hyperparametrov\n",
    "gbt = train_and_evaluate_model(train_df=train_prepared, val_df=None, test_df=test_prepared, model_type=\"gbt\", grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "165dafcf-f8ee-4ebd-a5b3-960f532b7027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimalizácia hyperparametrov pre GBT\n",
      "Najlepšie hyperparametre:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix GBT:\n",
      "Predicted/Actual        0.0       1.0       2.0\n",
      "            0.0     143706        35         0\n",
      "            1.0       7039     16845         2\n",
      "            2.0        957       624      1664\n",
      "\n",
      "Výsledky pre GBT:\n",
      "Accuracy:  0.949\n",
      "Precision: 0.950\n",
      "Recall:    0.949\n",
      "F1 Score:  0.945\n",
      "Matthews Correlation Coefficient (MCC) GBT: 0.803\n"
     ]
    }
   ],
   "source": [
    "# S optimalizáciou hyperparametrov\n",
    "gbt_optimized = train_and_evaluate_model(train_df=train_prepared, val_df=val_prepared, test_df=test_prepared, model_type=\"gbt\", grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca0b5c-845b-4481-8df7-2041482ea61c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
